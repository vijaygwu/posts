{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+5muH1F3sCfAzo9gXV1YT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijaygwu/classideas/blob/main/LowRankFact.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of a generic low rank factorization\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create a user-item matrix (e.g., user ratings)\n",
        "# This is a simple example; you should replace this with your data\n",
        "user_item_matrix = np.array([\n",
        "    [5, 4, 0, 1, 0],\n",
        "    [4, 0, 3, 1, 0],\n",
        "    [1, 0, 0, 5, 4],\n",
        "    [0, 1, 5, 4, 5]\n",
        "])\n",
        "\n",
        "# Perform SVD factorization\n",
        "U, Sigma, VT = np.linalg.svd(user_item_matrix, full_matrices=False)\n",
        "\n",
        "# Specify the desired low rank (number of latent factors)\n",
        "k = 2\n",
        "\n",
        "# Reconstruct the matrix with a lower rank approximation\n",
        "U_k = U[:, :k]\n",
        "Sigma_k = np.diag(Sigma[:k])\n",
        "VT_k = VT[:k, :]\n",
        "\n",
        "user_item_matrix_approx = np.dot(U_k, np.dot(Sigma_k, VT_k))\n",
        "\n",
        "# Now, user_item_matrix_approx contains the low-rank approximation of the original matrix\n",
        "print(\"Original User-Item Matrix:\")\n",
        "print(user_item_matrix)\n",
        "print(\"\\nLow-Rank Approximation (k=2):\")\n",
        "print(user_item_matrix_approx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiP9UyXo3t3I",
        "outputId": "6a159a09-904f-4bb0-d4c3-9de4d5bb828e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original User-Item Matrix:\n",
            "[[5 4 0 1 0]\n",
            " [4 0 3 1 0]\n",
            " [1 0 0 5 4]\n",
            " [0 1 5 4 5]]\n",
            "\n",
            "Low-Rank Approximation (k=2):\n",
            "[[ 5.41568326  2.90021003  0.96027988  0.79937254 -0.42029949]\n",
            " [ 3.33507949  1.81162257  1.24419831  1.4210575   0.72236071]\n",
            " [ 0.52868834  0.37944563  2.54831089  3.57012382  3.64807301]\n",
            " [ 0.46425301  0.38309582  3.50922726  4.94395384  5.11445954]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Decompose a dense layer using SVD\n",
        "def decompose_dense_layer(layer, rank):\n",
        "    weights = layer.weight.data.numpy()\n",
        "    biases = layer.bias.data.numpy()\n",
        "\n",
        "    # SVD decomposition\n",
        "    U, S, Vt = np.linalg.svd(weights, full_matrices=False)\n",
        "\n",
        "    # Take the first 'rank' components\n",
        "    U_approx = U[:, :rank]\n",
        "    S_approx = np.sqrt(S[:rank])  # Taking square root of singular values\n",
        "    Vt_approx = Vt[:rank, :]\n",
        "\n",
        "    W1 = torch.tensor(U_approx, dtype=torch.float32)\n",
        "    W2 = torch.tensor(np.dot(np.diag(S_approx), Vt_approx), dtype=torch.float32)\n",
        "\n",
        "    return W1, W2, biases\n",
        "\n",
        "# Create the original model\n",
        "class OriginalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OriginalModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the rank for decomposition\n",
        "rank = 512\n",
        "\n",
        "# Create the original model instance\n",
        "original_model = OriginalModel()\n",
        "print(original_model)\n",
        "\n",
        "# Decompose the dense layer\n",
        "W1, W2, biases = decompose_dense_layer(original_model.fc1, rank)\n",
        "\n",
        "# Create a new model with decomposed layers\n",
        "class DecomposedModel(nn.Module):\n",
        "    def __init__(self, rank):\n",
        "        super(DecomposedModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, rank, bias=False)\n",
        "        self.fc2 = nn.Linear(rank, 1024, bias=True)\n",
        "        self.fc3 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Create the new model instance\n",
        "new_model = DecomposedModel(rank)\n",
        "\n",
        "# Set weights for the decomposed layers\n",
        "new_model.fc1.weight.data = W1\n",
        "new_model.fc2.weight.data = W2\n",
        "new_model.fc2.bias.data = torch.tensor(biases, dtype=torch.float32)\n",
        "\n",
        "# Print the new model summary\n",
        "print(new_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnu5Nj787R0J",
        "outputId": "e9768117-5de6-48fa-94bc-dc80a73f645e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OriginalModel(\n",
            "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n",
            "DecomposedModel(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=False)\n",
            "  (fc2): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}