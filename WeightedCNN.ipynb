{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNr4vDkEtfAs6Lc41WOCHwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijaygwu/classideas/blob/main/WeightedCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0bQbiXWUHrp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Config:\n",
        "    train_data_path = '/Users/vraghavan/Desktop/ClassificationTest/dogs-vs-cats/train'\n",
        "    test_data_path = '/Users/vraghavan/Desktop/ClassificationTest/dogs-vs-cats/test1'\n",
        "    model_save_path = 'optimizer_cnn_torch.pth'\n",
        "    epochs = 10\n",
        "    learning_rate = 0.001\n",
        "    batch_size = 32\n",
        "    positive_label = \"dog\"\n",
        "    negative_label = \"cat\"\n",
        "    data_transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "class ComplexCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ComplexCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.max_pool = nn.MaxPool2d(2, 2)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.conv1(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = self.leaky_relu(self.conv2(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = self.leaky_relu(self.conv3(x))\n",
        "        x = self.max_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class AugmentedImageDataset(Dataset):\n",
        "    def __init__(self, data_root, transform=None):\n",
        "        self.image_files = [f for f in os.listdir(data_root) if f.endswith('.jpg')]\n",
        "        self.data_root = data_root\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def apply_augmentation(self, image):\n",
        "        if random.random() > 0.5:\n",
        "            image = F.hflip(image)\n",
        "        angle = random.randint(-10, 10)\n",
        "        image = F.rotate(image, angle)\n",
        "        return image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.data_root, self.image_files[idx])\n",
        "        image = Image.open(image_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        image = self.apply_augmentation(image)\n",
        "        label = 1 if Config.positive_label in self.image_files[idx] else 0\n",
        "        return image, label\n",
        "\n",
        "def visualize_loss_and_accuracy(losses, accuracies):\n",
        "    epochs = range(1, len(losses) + 1)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, losses, '-o')\n",
        "    plt.title('Loss over epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracies, '-o')\n",
        "    plt.title('Accuracy over epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "def train_and_evaluate(optimizer_type, augmentation_type, regularization_type):\n",
        "    train_dataset = AugmentedImageDataset(Config.train_data_path, transform=Config.data_transform)\n",
        "    class_counts = [0, 0]\n",
        "    for _, label in train_dataset:\n",
        "        class_counts[label] += 1\n",
        "    class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
        "    class_weights = class_weights / class_weights.sum()\n",
        "    weights = [class_weights[label] for _, label in train_dataset]\n",
        "    sampler = WeightedRandomSampler(weights, len(train_dataset), replacement=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, sampler=sampler)\n",
        "    test_loader = DataLoader(ImageDataset(Config.test_data_path, transform=Config.test_transform),\n",
        "                             batch_size=Config.batch_size, shuffle=False)\n",
        "    model = ComplexCNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if optimizer_type == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=Config.learning_rate)\n",
        "    elif optimizer_type == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=Config.learning_rate, momentum=0.9)\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=Config.learning_rate)\n",
        "\n",
        "    train_losses, train_accuracies = [], []\n",
        "    for epoch in range(Config.epochs):\n",
        "        model.train()\n",
        "        running_loss, correct_predictions = 0.0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            if regularization_type == 'mixup':\n",
        "                mixed_images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=0.4)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(mixed_images)\n",
        "                loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
        "            elif regularization_type == 'cutmix':\n",
        "                mixed_images, labels_a, labels_b, lam = cutmix_data(images, labels, alpha=1.0)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(mixed_images)\n",
        "                loss = cutmix_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
        "            else:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "        average_loss = running_loss / len(train_loader)\n",
        "        accuracy = correct_predictions / len(train_loader.dataset)\n",
        "        train_losses.append(average_loss)\n",
        "        train_accuracies.append(accuracy)\n",
        "        print(f\"Epoch [{epoch+1}/{Config.epochs}], Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), Config.model_save_path)\n",
        "    visualize_loss_and_accuracy(train_losses, train_accuracies)\n",
        "\n",
        "def test_single_image(image_path, model):\n",
        "    # ... (rest of the test_single_image function)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description='Train the model and/or Predict a given image.')\n",
        "    parser.add_argument('--image_path', type=str, help='Path to the input image. If provided, model prediction will be executed.')\n",
        "    parser.add_argument('--optimizer', type=str, choices=['adam', 'rmsprop', 'sgd'], default='adam', help='Choose optimizer (adam, rmsprop, sgd)')\n",
        "    parser.add_argument('--augmentation', type=str, choices=['none', 'simple'], default='none', help='Choose data augmentation type (none, simple)')\n",
        "    parser.add_argument('--regularization', type=str, choices=['none', 'mixup', 'cutmix'], default='none', help='Choose regularization type (none, mixup, cutmix)')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.augmentation == 'simple':\n",
        "        Config.data_transform = transforms.Compose([\n",
        "            transforms.Resize((64, 64)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    if not args.image_path:\n",
        "        train_and_evaluate(args.optimizer, args.augmentation, args.regularization)\n",
        "    else:\n",
        "        model = ComplexCNN().to(device)\n",
        "        model.load_state_dict(torch.load(Config.model_save_path))\n",
        "        model.eval()\n",
        "        test_single_image(args.image_path, model)\n"
      ]
    }
  ]
}